\chapter{Foundation and Related Work}
\label{chp:FouRelWor}
This chapter presents the related work on the data collection domain, which mainly includes surveys. The factors affecting response rates. Comparison of exisitng products in the market to aid data collection. 

\section{Surveys and data collection}
\label{sec:1:SurDatCol}
A Survey is defined as a system for collecting information \citep[page 3]{Sue2011}. It helps to learn about people's opinions and behaviors \citep{DillmanDonA.SmythJoleneD.Christian2009}.  The produced data during or at the completion of the survey belong to the data collection process. Therefore, data collection is a fundamental step to produce useful data to enable analyzes on researches \citep[page 149]{Groves2009}. These researches include but not limited to many disciplines like sociology, statistics, psychology, marketing, economics, and heath sciences. 

\subsection{Email surveys}
\label{sec:2.1.1:EmaSur}

Comparing many different characteristics of surveys and interviews, the concerns regarding speed and cost make the most powerful differences \citep{Sproull1986, Schaefer1998}. Email surveys offers more rapid surveying than other methods including regular mail and telephone surveys. In addition to that, email surveys are inexpensive since it removes the postage, paper and printing, and interview costs \citep{Schaefer1998}.
\vspace{1cm}

Sproull \citep{Sproull1986} identified the characteristics of email with a organizational research, within a Fortune 500 office products and systems manufacturer, who were using email for 12 years in the organization and over 80 percent of all employees in the selected unit have email access at the time of the research. Selected candidates are separated into two groups. The data collection protocol within the organization asked each of the group's participants series of questions regarding their 3-day old email inbox. Both groups filled out the questionnaire and answer open-ended questions either electronically or in writing.
\vspace{1cm}

The result of the study indicated that the average duration of data collection time for email version was less than a week, which is half of the duration of the written version. While the response rate of email version was 73 percent, conventional written version's rate was 87. The percentage of missing data in the questionnaires was .2 percent in the written version, and 1.4 in the email version. There were no differences in mean answers in email version comparing written questionnaire.
\vspace{1cm}

In an another study from Sheehan and Hoy \citep{Sheehan2006}, where they administered only an email survey to query individuals about their on-line behaviors and their attitudes and opinions regarding privacy. They have reached the shortest response time with 3.65 days comparing with earlier studies conducted until that time (See table~\ref{tab:sur_res_met}).

\begin{center}
	%\renewcommand{\arraystretch}{2}
	\tiny
	\setlength{\tabcolsep}{5pt}
    \begin{longtable}{ | p{2cm} | p{2cm} | p{2cm} | p{0.75cm} | p{0.75cm} | p{1cm} | p{1cm} | p{0.5cm} | }
	\caption[Summary of Survey Research Methods Using E-mail]{Summary of Survey Research Methods Using E-mail \citep{Sheehan2006}} \label{tab:sur_res_met} \\
    
	\hline
	\multicolumn{1}{|p{2cm}|}{\textbf{Author}} & \multicolumn{1}{p{2cm}|}{\textbf{Response Sample}} & \multicolumn{1}{p{2cm}|}{\textbf{Survey Topic}} & \multicolumn{1}{p{0.75cm}|}{\textbf{Sample Size}} & \multicolumn{1}{p{0.75cm}|}{\textbf{Usable Sample}} & \multicolumn{1}{p{1cm}|}{\textbf{Method}} & \multicolumn{1}{p{1cm}|}{\textbf{Response Rate}} & \multicolumn{1}{p{0.5cm}|}{\textbf{Time (days)}} \\ \hline
	\endfirsthead
	
	\multicolumn{8}{c}%
	{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
	\hline
	\multicolumn{1}{|p{2cm}|}{\textbf{Author}} & \multicolumn{1}{p{2cm}|}{\textbf{Response Sample}} & \multicolumn{1}{p{2cm}|}{\textbf{Survey Topic}} & \multicolumn{1}{p{0.75cm}|}{\textbf{Sample Size}} & \multicolumn{1}{p{0.75cm}|}{\textbf{Usable Sample}} & \multicolumn{1}{p{1cm}|}{\textbf{Method}} & \multicolumn{1}{p{1cm}|}{\textbf{Response Rate}} & \multicolumn{1}{p{0.5cm}|}{\textbf{Time (days)}} \\ \hline
	\endhead

	\multicolumn{8}{|r|}{{Continued on next page}} \\ \hline
	\endfoot

	\multicolumn{8}{|r|}{{*Differences not significant}} \\ \hline
	\endlastfoot

	
    \multirow{2}{2cm}{Kiesler \& Sproull (1986)}  & \multirow{2}{2cm}{Employees of a Fortune 500} & \multirow{2}{2cm}{Corporate Communication} & 115 & 77 & Mail & 67\% & 10.8 \\ \cline{4-8}
	&  &  & 115 & 86 & Email & 75\% & 9.6 \\ \hline
    \multirow{2}{2cm}{Parker (1992)}  & \multirow{2}{2cm}{Employees of AT\&T} & \multirow{2}{2cm}{Internal Communication} & 70 & 27 & Mail & 38\% & NA \\ \cline{4-8}
	&  &  & 70 & 48 & Email & 68\% & NA \\ \hline
    \multirow{2}{2cm}{Schuldt \& Totten (1994)}  & \multirow{2}{2cm}{Marketing \& MIS Professors (US)} & \multirow{2}{2cm}{Shareware Copying} & 200 & 113 & Mail & 56.5\% & NA \\ \cline{4-8}
	&  &  & 218 & 42 & Email & 19.3\% & NA \\ \hline
    \multirow{2}{2cm}{Mehta \& Sivadas (1995)}  & \multirow{2}{2cm}{Usenet Users} & \multirow{2}{2cm}{Internet Communication} & 309 & 173 & Mail & 56.5\%* & NA \\ \cline{4-8}
	&  &  & 182 & 99 & Email & 54.3\%* & NA \\ \hline
    \multirow{2}{2cm}{Tse, et al (1995)}  & \multirow{2}{2cm}{University Population (HK)} & \multirow{2}{2cm}{Business Ethics} & 200 & 54 & Mail & 27\% & 9.79 \\ \cline{4-8}
	&  &  & 200 & 12 & Email & 6\% & 8.09 \\ \hline
    \multirow{2}{2cm}{Bachman, Elfrink \& Vazzana (1996)} & \multirow{2}{2cm}{Business School Deans} & \multirow{2}{2cm}{TQM} & 224 & 147 & Mail & 65.6\% & 11.18 \\ \cline{4-8}
	&  &  & 224 & 117 & Email & 52.5\% & 4.68 \\ \hline
    Sheehan \& Hoy (1997) & University Population (Southeast US) & Privacy and New Technology & 580 & 274 & Email & 47.2\% & 4.7 \\ \hline
    \multirow{2}{2cm}{Smith (1997)} & \multirow{2}{2cm}{Web presence} & \multirow{2}{2cm}{Business Activities} & 150 & 11 & Email survey & 8\% & NA \\ \cline{4-8}
	&  &  & 150 & 42 & Email solicit & 11.3\% & NA \\ \hline
	\multirow{4}{2cm}{Schillewaert, Langerak and Duhamel (1998)} & \multirow{4}{2cm}{Web users in Belgium} & \multirow{4}{2cm}{Attitudes toward the Web} & 430 & 125 & Email & 31\% & NA \\ \cline{4-8}
	&  &  & 62.5M & 110 & Ad in magazine & 0\% & NA \\ \cline{4-8}
	&  &  & 4000 & 67 & USENET Posting & 2\% & NA \\ \cline{4-8}
	&  &  & 7500 & 51 & Hyperlinks & 0.68\% & NA \\ \hline 
    \multirow{4}{2cm}{Weible and Wallace (1998)} & \multirow{4}{2cm}{MIS Professors (US)} & \multirow{4}{2cm}{Internet Use} & 200 & 70 & Mail & 35.7\% & 12.9 \\ \cline{4-8}
	&  &  & 200 & 50 & Fax & 30.9\% & 8.8 \\ \cline{4-8}
	&  &  & 200 & 48 & Email & 29.8\% & 6.1 \\ \cline{4-8}
	&  &  & 200 & 52 & Web form & 32.7\% & 7.4 \\ \hline
    \multirow{2}{2cm}{Schaefer and Dillman (1998)} & \multirow{2}{2cm}{University Faculty} & \multirow{2}{2cm}{Unknown} & 226 & 130 & Mail & 57.5\%* & 14.39 \\ \cline{4-8}
	&  &  & 226 & 131 & Email & 58.0\%* & 9.16 \\ \hline
    \end{longtable}
\end{center}


In addition to speed of the email surveys, cost benefits have been indicated in Sheehan and Hoy's study \citep{Sheehan2006} also concluded that email is an extremely cost-efficient method for data collection, where the total cost estimated at \$470 (\$30 for printing out the responses, \$440 for 22 hours computer time to download surveys for printing) while postal mail is estimated at \$6,500 (printing, postage, survey, and reminder mailing).
\vspace{1cm}

In another study from Mavis and Brocato \citep{Mavis1998}, the email survey was nearly seven times cost efficient than postal survey. This includes labor hours, survey materials like booklets, mailing labels, envelopes, and postage costs. Total time spent into postal survey was 33 hours, but it only required 12 hours for the email survey. Final cost was \$503.36 for postal survey, whose \$305.36 was spent for postage part, and remaining \$198 was spent for student labor cost. The only cost resultant from email survey was student labor cost, which was total \$72.
\vspace{1cm}

Moreover, Paolo, et al., \citep{Paolo2009} reported that people made longer open-ended response comments in email version of the survey comparing with mail version. While the average number of words per comment was 58.33\% in the mail version, and it was 75.40\% in the email version of the survey. Bachmann, et al., \citep{BachmannD.ElfrinkJ.&Vazzana1999} had the same finding in 1995 and 1998, where open-ended questions were responded much likely by email recipients than the mail recipients. In the latter study conducted in 1998, researches also found that email respondents were more likely to expand their answers, even it was not suggested by the survey, resulting more candid responses than mail surveys. Responses to open-ended questions is one of the important measure to determine the quality of the returned surveys \citep{BachmannD.ElfrinkJ.&Vazzana1999}.
\vspace{1cm}

Given these advantages and positive benefits of email surveys, next section will provide information about surveys errors applicable to all type of surveys.

\subsection{Survey Errors}
\label{sec:2.1.2:SurErr}
Sample surveys are quantitative estimation of the distribution of a characteristics in a population by obtaining this information from a small portion of the corresponding population \citep{Dillman1991}. To generalize results from a small portion, which is a sample, to a population, following sources of errors needs to be considered \citep[page 9]{Dillman2006} \citep{Dillman1991}:

\paragraph{Sampling Error}
The more number of people surveyed, the large degree of precision can be achieved. Therefore, the limitations on the number of people surveyed are considered under the sampling error. For example. while public opinion of 100 people results \(\pm\textdollar10\%\) of the true percent, 2,200 people results higher confidence with the percent of \(\pm\textdollar2\%\) \citep[page 9]{Dillman2006}. The surveys relying on predefined list of recipients considered that the list is randomly generated or with a systematic sampling. Hence, it has got little research to reduce sampling errors comparing with face-to-face interviews in which multistage cluster designs\footnote{Cluster sampling selects preexisting groups of population elements instead of a single element of the population \citep[page 106]{Groves2009}. Departments of a university or households in a block represents clusters of people. When the allocation of those sampling resources are stratified and based on multiple stages, frequently three stages, it is called multistage cluster sampling. First step selects the sample of counties, followed by the blocks within those counties, and finally the dwellings from the chosen blocks \citep{Scott1969}.} are used due to cost and time limitations \citep[page 106]{Groves2009} \citep{Dillman1991}.

\paragraph{Coverage Error}
When the list of surveyed people does not include all the elements of the population, coverage error happens \citep[page 9]{Dillman2006}. Coverage error is considered one of the biggest issue of surveys since while surveying general public \citep{Dillman1991}.

\paragraph{Measurement Error}
When a respondent's answer is hard to evaluate or cannot be compared with other respondent's answers or there are inconsistencies between the observable variables like opinions, behaviors, or attributes and the survey responses, measurement error happens \citep[page 9]{Dillman2006} \citep{Dillman1991}. The possible reasons might depend on poor wording or order of the questions or the characteristics of the surveyed person such as incapability to provide correct answers or motivational factors \citep{Dillman1991}.

\paragraph{Nonresponse Error}
When there are large amount of people who do not response, and their characteristics are different from the ones who responded, then it results nonresponse error \citep[page 9]{Dillman2006}. Low response has been considered a major problem, and many researches have focused on improving the response rates \citep{Dillman1991}.

\section{Response Rate Influences}
\label{sec:2.2:ResRatInf}

As mentioned in the previous section, one of the survey errors is the nonresponse error. Researchers have concerns regarding response rates, since responses coming from survey participants may be substantially different from those of nonrespondents, which will result in a biased estimate of representation of the population \citep{Bogen1996}.
\vspace{1cm}

Low response rate was even considered shortfall of the email methodology despite to its advantages \citep{BachmannD.ElfrinkJ.&Vazzana1999}. In table~\ref{tab:sur_res_met}, there are nine studies where both postal mail and email are compared side by side. Out of those nine studies, four of them show high response rate on postal mail, three of them got higher response on email. and two studies did not show any significant differences. Parker's (1992) study of AT\&T employees was the only study which got an acceptably high response rate by email. Schaefer and Dillman attributed this fact to the novelty of email and sent emails were carefully examined instead of considered company junk email \citep{Schaefer1998}. Mavis and Brocato stated that studies cited by others in support of email surveys, also shown in table~\ref{tab:sur_res_met}, did not compare email data collection with more traditional methods, and their study design and analyses varied greatly \citep{Mavis1998}. Sheehan and Hoy also takes the attention to many of these studies' small and homogeneous population, therefore it may not represent larger population groups' response tendencies \citep{Sheehan2006}.
\vspace{1cm}

Therefore, researchers investigated on how to increase response rates at email communication. Schaefer and Dillman (1998) conclude that even though, the technology for email is quite different from well established postal mail surveying methods, the communication is considered similar to self-administrated questionnaires delivered by post. Hence, the techniques used to increase response rates on postal mail can be applied to develop a email methodology \citep{Schaefer1998}. Following techniques are the ones where researchers focused on their effects on response rates.

\subsection{Length}
\label{sec:2.2.1:Leng}
For many people the time required to spend on survey is considered the biggest cost \citep[page 26]{DillmanDonA.SmythJoleneD.Christian2009}. The study from Heberlein and Baumgertner (1978) also states that the length of the survey has a negative effect on mail survey response rates, where they stated that each additional question reduces responses by .05\% \citep{Heberlein1978}. On the other hand, Bradburn (1978) suggests that the length of the survey is correlated with its importance, therefore it will increase the efforts both on researchers and respondents side resulting a higher response rate \citep{Bradburn1978}. Bogen (1996), in his literature review, concluded that the relationship between interview length and nonresponse is week and inconsistent \citep{Bogen1996}.

\subsection{Multiple Contacts}
\label{sec:2.2.2:MultCont}
Researchers found that the number of attempts to contact people increases the response rates \citep{Heberlein1978,Schaefer1998}. The scenarios for multiple contact include pre-notification contact, which is a brief notice for the main request, and follow-up contacts aiming to the people who did not respondent at the initial contact. Heberlein and Baumgertner (1978) showed that follow-up mailing has a mean return rate of 19.9\% at the initial contact, and continued with 11.9\% and 10.0\% for the second and third contacts, respectively \citep{Heberlein1978}. Schaefer and Dillman (1998) also stated the same conclusion for the multiple contacts for email in their literature research. According to this, the average response rate for email surveys with a single contact was 28.5\% while 41\% and 57\% for two and more than two contacts, respectively \citep{Schaefer1998}.

\subsection{Personalization}
\label{sec:2.2.3:Pers}
Personalization has been addressed as an important factor to increase response rates by many researchers \citep{Dillman1991,Schaefer1998}. It builds a connection between the respondent and researcher by making the respondent feel important, and drawing the respondent from out of the group \citep[page 272]{DillmanDonA.SmythJoleneD.Christian2009}. Dillman and Frey (1974) conducted a study to see the effects of personalization, where they reached half of an university alumni sample via personalized cover letters, while the other half got unpersonalized letters. The personalization treatment included personal salutations and real signatures on the mails. They achieved nearly 9\% greater response rates for the personalized group \citep{Dillman1974a}. It is also stated that this type of personalization techniques can be also applied to emails \citep{Schaefer1998}. In the next section, we will continue with the applications of personalization in emails, and give the results of some studies.

\section{Personalization of emails}
\label{sec:2.3:PersEmai}
Studies on mail surveys showed that personalization increases the response rates \citep{Dillman1991,Schaefer1998}. Personalization is also important for email communication since it also builds a connection between the respondent and researcher as in the mail surveys studies, and make them feel more important and valued \citep[page 272]{DillmanDonA.SmythJoleneD.Christian2009}. With this argument, Dillman, et al., emphasized the social exchange theory\footnote{Social exchange theory was considered as a frame of reference to other theories rather than a theory by itself. It implies a two-sided, mutually contingent and rewarding transactions or exchanges \citep{Emerson1976}.} of the personalization of the email.
\vspace{1cm}

On the other hand, Barron and Yechiam (2002) stressed on the sociopsychological phenomenon, the diffusion of responsibility, which is also an outcome of volunteer's dilemma. In the volunteer's dilemma one player is needed to volunteer in order to reach the outcome preferred by all the others in the game. However, each person might be inclined to hoping that somebody else will be volunteer, resulting a higher utility of not volunteering than volunteering. According to this, the more people in the group size, the less probability of volunteering will result, which produce the diffusion of responsibility effect \citep{Barron2002}. In order to experiment the effect of diffusion of responsibility in the context of email requests, they sent emails asking for help either to single addresses or to a list of five addresses. In the email body (see Appendix A), a fictitious graduate student asked a question to know if the university has a biology faculty, whose answer was well known to anyone familiar with the institute. The result of the study showed that the proportion of replies where they use single email address in the "To" field got 20\% higher response than the replies where they used groups of email addresses. In addition, the study qualified the given responses according to its helpful level, and the proportion of "very helpful" replies in the single email address condition was 187\% higher than the groups of email addresses condition.
\vspace{1cm}

In an another study by Heerwegh (2005), personalization was applied to the salutations in the emails. The randomly drawn 2,540 samples from the student database of Katholieke Universiteit Leuven, Belgium was separated into equally sized two groups. In the non-personalized group, the salutation of "Dear student" was used, while in the personalized group "Dear [First name] [Last name]" was used. The email content was an invitation to a web survey which was about adolescent attitudes towards marriage and divorce. The result of the study showed that the personalization applied group got 6.9\% higher login rate to the survey than the unpersonalized group. Therefore, they concluded that increased response rates were in line with social exchange theory and with the diffusion of responsibility theory \citep{Heerwegh2005}.
\vspace{1cm}

In addition to personalization of salutations on the emails, Joinson and Reips (2007) stated the power of its combination with the power or status of the sender. In the study, a group of discussion panel students of Open University UK were sent an email invitation to complete a survey. Panel members were assigned to one of the conditions where salutation was modified in "Dear student", "Dear John Doe", and "Dear John". The sender power was manipulated on the first and last lines of the emails by assigning a neutral power saying that "From <name> (Strategy, Planning, and Partnerships), The Open University" and a high power "From Professor <name>, Pro-vice chancellor (Strategy, Planning, and Partnerships), The Open University". The results showed that the highest response rate was achieved when a personalized invitation came from a high power source and lowest when an impersonal one came from a neutral power source (See table~\ref{tab:pow_sal_res}). The possible reason for this was stated as personalized salutations increase people's sense of identifiability,  and its combination with a high power audience increase socially desirable, strategic behavior \citep{Joinson2007}.

\begin{table}[!ht]
\begin{center}
	%\renewcommand{\arraystretch}{2}
	%\tiny
	%\setlength{\tabcolsep}{5pt}
	\caption[Power, salutation and response rates (raw and \%)]{Power, salutation and response rates (raw and \%) \citep{Joinson2007}} \label{tab:pow_sal_res}
    \begin{tabular}{ p{3cm} p{3cm}  p{3cm}  p{3cm} }
	\hline
	& \textbf{Dear Student} & \textbf{Dear John Doe} & \textbf{Dear John} \\ \hline
	\textbf{Neutral power} & 143 (40.1) & 158 (44.4) & 166 (46.6) \\
	\textbf{High power} & 150 (42.1) & 154 (43.3) & 190 (53.4) \\ \hline
    \end{tabular}
\end{center}
\end{table}

As aforementioned studies showed that different forms of personalization increase the response rates in email communication. However, it has become very easy to add personalized information into email thanks to the softwares. Dillman, et al. (2009) stated that over-personalization using software tools might easily result impersonal messages, and gave an example \citep[page 237-238]{DillmanDonA.SmythJoleneD.Christian2009}: "Dear Don Dillman, I am writing to inform you and your wife Joye that the XYZ Company has created a new dog food that we are sure your Boston Terrier, Crickett, will find to be very tasty. We would like to send a free sample to your home in Pullman, Washington." In this message, there is overwhelmed personalization with the usage of person's wife, their dog's type and name, and their home address. Moreover, experienced email users can identify if a message is written by a person or computer generated by looking appearance of one's name in certain locations, and similar patterns for other information \citep[page 272]{DillmanDonA.SmythJoleneD.Christian2009}. Therefore, it becomes difficult to have a correct amount and tone of personalization. The more daily interaction with digital devices will make the true authentic personalization more rare, hence achieving it will make it more important and effective \citep[page 238]{DillmanDonA.SmythJoleneD.Christian2009}.


 


\begin{comment}
 .... talk about dillman and finish, it is opposite idea, so keep it in this section, sonra overview of tools, de ama once be review et hocaya yolla

--> bunu sorunlar kisminda yazabilirisin, niye CRM ihtiyac duydugunu acikliyor: personalization lost its effect on recent years cause of programs p152 dillman ebook 2007 - dillman kitap p237
--> E14 p379 da mail be email aslinda ayni diyor.
--> M1, there is a table showing response rate comparison of email vs paper for many studies. USE IT
--> Mention about which of the errors are not applicable to us. Eg.g sampling since we can predefined list of people
--> 10.1.1.189.3715.pdf "Assistance: The Work Practices of Human Administrative Assistants and their Implications for IT and Organizations"speak about the assistance support
--> Bi section adi bu olsun, survey uzerine yazdiklarin bittikten sonra: The issues with email communication
--> Burden on the Researcher E21p442, bunu sonra anlat IYI

--> Talked about the 4 issues of survey in here, and those issues are applicable to emails
--> Compare Web surveys and EMail
--> write about low response rate comparing with mail
--> 7 pages, then comparison of existing products, then crowsourcing (MAYBE you can write about assistant support using Michael's paper), then first prototype, then final, mention about the improvements
--> A chapter about assistance support 10.1.1.189.3715.pdf "Assistance: The Work Practices of Human Administrative Assistants and their Implications for IT and Organizations"
--> Write about people's email life PIP_Work_Email_Report.pdf.pdf


Previously known data collection methods like regular which includes questionnaires where respondents fill and post back, or phone interviews, or face-to-face interviews have got additional options by the development of technology like web and email.
\vspace{1cm}

A first comprehensive high response rate achieved mail survey is done at 1978 \citep[page 3]{Dillman2006}.
The first web survey, which was conducted on 1994 by James E. Pitkow and Margaret M. Recker, had an aim to demonstrate that the web as a survey medium. During that that estimated internet users were only 15 million \citep{Lewis1993}. The survey was posted one of the newsgroup, and got 4,777 responses during its one month online period.

\end{comment}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 